---
title: "R Notebook"
output: github_document
---
```{r}
```

 Chargement du package dada2
# Ce package est utilisé pour l'analyse de séquences d'ADN issues du séquençage haut débit (NGS),
#dans ce tutoriel ce  pour les gène 16S
# Il permet de filtrer, corriger, assembler et classifier les séquences afin d'obtenir des ASVs.
# Chargement du package dada2
```{r}
library(dada2)
```

# Vérification de la version du package dada2 installée
packageVersion("dada2")
```{r}
library(dada2); packageVersion("dada2")
```


# Définition du chemin où se trouvent mes fichiers fastq (les données brutes de séquençage Illumina)
# Ici, le chemin est "~/MiSeq_SOP" : 
#   - "~" correspond à mon répertoire utilisateur (home directory).
#   - "MiSeq_SOP" est le dossier qui contient mes fichiers .fastq après décompression.

```{r}
setwd("/home/rstudio/tuturiol_sow")
path <- "~/MiSeq_SOP" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```
# Les fichiers FASTQ forward et reverse suivent un format de nommage standard :
# Exemple : SAMPLENAME_R1_001.fastq et SAMPLENAME_R2_001.fastq
#   - R1 = lectures forward (lecture avant)
#   - R2 = lectures reverse (lecture arrière)
#   - "SAMPLENAME" = identifiant de ton échantillon

# On crée une liste des fichiers forward (R1)
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))

# On crée une liste des fichiers reverse (R2)
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))

# Extraction des noms d'échantillons
# basename(fnFs) → garde seulement le nom du fichier (pas le chemin complet)
# strsplit(..., "_") → découpe le nom du fichier en morceaux séparés par "_"
# sapply(..., `[`, 1) → prend le 1er morceau (donc le nom de l'échantillon avant le "_")
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)


```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```


# Affichage des profils de qualité pour les 2 premiers fichiers forward 
```{r}
plotQualityProfile(fnFs[1:2])
```

# Affichage des profils de qualité pour les 2 premiers fichiers reverse
```{r}
plotQualityProfile(fnRs[1:2])
```
# Création des chemins de sortie pour les fichiers filtrés (lectures forward)
# On utilise file.path() pour faire un chemin complet :
#   - "path" = dossier principal (~/MiSeq_SOP)
#   - "filtered" = sous-dossier où seront stockés les fichiers filtrés
#   - paste0() le nom de l’échantillon avec le suffixe "_F_filt.fastq.gz"
# meme chose pour les lectures reverse (R2), suffixe "_R_filt.fastq.gz"
# On associe chaque fichier forward filtré à son nom d’échantillon
names(filtFs) <- sample.names
# Idem pour les fichiers reverse filtrés
names(filtRs) <- sample.names

```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```

# Filtrage et tronquage des lectures forward et reverse
out <- filterAndTrim(
#fnFs,fichiers FASTQ forward d’origine
#filtFs,chemins de sortie pour forward filtrés
#fnRs,  fichiers FASTQ reverse d’origine
# filtRs, chemins de sortie pour reverse filtrés
# truncLen = c(240,160),  Longueurs de tronquage : 240 bases pour R1, 160 pour R2
# maxN = 0, Aucun N autorisé (bases indéterminées)
#maxEE = c(2,2),Maximum attendu d’erreurs : 2 pour forward, 2 pour reverse
#truncQ = 2, Tronquer à partir d’une base < Q2 (très basse qualité)
#rm.phix = TRUE,Supprime les lectures correspondant au contrôle PhiX
#compress = TRUE, Fichiers de sortie compressés en .gz
#multithread = F, Sur Windows mettre FALSE, sur Linux/Mac on peut mettre TRUE

```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=F) # On Windows set multithread=FALSE
head(out)
```

# Apprentissage du modèle d'erreur sur les lectures forward filtrées

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```

# Apprentissage du profil d’erreurs pour les reads reverse filtrés
```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```

# Affichage du modèle d’erreurs pour les reads forward
```{r}
plotErrors(errF, nominalQ=TRUE)
```

# Inférence des variants de séquences exactes (ASVs) sur les fichiers forward
#Cela te dit combien de lectures ont été conservées et combien de variants uniques (ASVs) ont été trouvés

```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
```

# Inférence des variants de séquences exactes (ASVs) sur les fichiers reverse
#Cela te dit combien de lectures ont été conservées et combien de variants uniques (ASVs) ont été trouvés
```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
```

#Utiles pour un aperçu global nombre d’uniques (ASVs “bruts”) par échantillon
```{r}
dadaFs[[1]]
```

# Fusion des lectures forward et reverse (R1 et R2)
#Affiche les premières lignes du tableau de résultats pour le 1er échantillon

```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```
# Construction de la table de séquences (ASV table)
# Dimensions de la table (nb d'échantillons x nb d’ASVs)
#Prend en entrée les résultats de mergePairs() (séquences fusionnées par échantillon)

```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
# Vérification de la distribution des longueurs des séquences (ASVs)
#construit une table de fréquence indiquant combien d’ASVs ont telle ou telle longueur.

```{r}
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```

# Suppression des séquences chimériques
# Dimensions de la nouvelle table (après suppression des chimères)
#Détecte les chimères = artefacts créés lors de la PCR, où deux séquences différentes s’assemblent faussement
#C’est une étape indispensable, car les chimères peuvent représenter jusqu’à 20–30 % des séquences dans un jeu 16S
#Resultat, Table d’ASVs nettoyée : seules les séquences biologiquement plausibles restent

```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```

# Calcul de la proportion de lectures non chimériques
#omme de toutes les lectures dans ta table avant suppression des chimères.
#donne donc la fraction de lectures conservées.

```{r}
sum(seqtab.nochim)/sum(seqtab)
```

# Fonction utilitaire : compte le nombre total de lectures uniques
# Construction du tableau de suivi
# Attribution des noms de colonnes
# Attribution des noms de lignes (noms d’échantillons)
# Affiche les 6 premières lignes du tableau
#Ça permet de visualiser les pertes à chaque étape (filtrage, débruitage, fusion, anti-chimères).
#On peut rapidement repérer un problème (ex : très faible taux de fusion ou énorme perte après suppression des chimères).

```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```
#Création d’un dossier "tax" dans ton répertoire utilisateur (home directory)
# C’est ici que j'ai stocké les fichiers de référence nécessaires à l’assignation taxonomique
# Téléchargement du jeu d’entraînement Silva v132 (classification des taxons jusqu’au genre)
# Téléchargement du fichier d’assignation au niveau espèce (Silva v132)


```{r}
dir.create("~/tax", showWarnings=FALSE)
download.file("https://zenodo.org/record/1172783/files/silva_nr_v132_train_set.fa.gz",
              destfile = "~/tax/silva_nr_v132_train_set.fa.gz",mode = "wb")
download.file("https://zenodo.org/records/1172783/files/silva_species_assignment_v132.fa.gz",
              destfile = "~/tax/files/silva_species_assignment_v132.fa.gz",mode = "wb")
            
```

# Assignation taxonomique des ASVs avec la base de référence SILVA v132
```{r}
taxa <- assignTaxonomy(seqtab.nochim, "~/tax/silva_nr_v132_train_set.fa.gz", multithread=TRUE)
```

# Ajout de l’assignation au niveau espèce à la matrice taxonomique
#Ici je lui donnes le fichier silva_species_assignment_v132.fa.gz qui contient des séquences de référence au niveau espèce.
```{r}
taxa <- addSpecies(taxa, "~/silva_species_assignment_v132.fa.gz")
```
# Copie de l’objet taxa pour l’affichage
# Suppression des noms de lignes (qui sont par défaut les séquences ASV)
# cette commande m'a permis d’afficher un aperçu lisible de ta taxonomie sans les séquences en guise de noms.

```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```

# Chargement du package DECIPHE
# Vérification de la version installée 
packageVersion("DECIPHER")
#Charge le package DECIPHER, développé pour l’analyse de séquences d’ADN/ARN

```{r}
library(DECIPHER); packageVersion("DECIPHER")
```


# Crée un objet de séquences ADN à partir des ASVs (colonnes de seqtab.nochim)
# Charge le jeu d’entraînement DECIPHER (SILVA) depuis un fichier .RData local
# Définition des rangs taxonomiques qui t’intéressent
ranks <- c("domain", "phylum", "class", "order", "family", "genus", "species")
# Convertit la liste d’objets 'Taxa' (renvoyée par IdTaxa) en matrice
# Nomme les colonnes par les rangs et les lignes par les séquences ASV (nucleotidiques)

```{r}
dna <- DNAStringSet(getSequences(seqtab.nochim)) # Create a DNAStringSet from the ASVs
  load("~/SILVA_SSU_r138_2_2024.RData") # CHANGE TO THE PATH OF YOUR TRAINING SET
ids <- IdTaxa(dna, trainingSet, strand="top", processors=NULL, verbose=TRUE) # use all processors
ranks <- c("domain", "phylum", "class", "order", "family", "genus", "species") # ranks of interest
# Convert the output object of class "Taxa" to a matrix analogous to the output from assignTaxonomy
taxid <- t(sapply(ids, function(x) {
        m <- match(ranks, x$rank)
        taxa <- x$taxon[m]
        taxa[startsWith(taxa, "unclassified_")] <- NA
        taxa
}))
colnames(taxid) <- ranks; rownames(taxid) <- getSequences(seqtab.nochim)
```
# Sélection des ASVs présents dans l'échantillon "Mock"
# On garde uniquement les ASVs avec une abondance > 0
# puis on les trie par abondance décroissante
# Affiche combien d'ASVs DADA2 a inféré dans le Mock community
#Dans un Mock community, on connaît le nombre d’espèces (ex. 20  dans mon cas).

```{r}
unqs.mock <- seqtab.nochim["Mock",]
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE) # Drop ASVs absent in the Mock
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")
```


# Charge les séquences de référence attendues pour le Mock community
# Le fichier "HMP_MOCK.v35.fasta" contient les séquences 16S des espèces connues
# Vérifie si chaque ASV trouvé dans le Mock correspond à une séquence de référence attendue
# Affiche combien d’ASVs correspondent exactement aux séquences de référence
#Ça permet de vérifier la précision de DADA2

```{r}
mock.ref <- getSequences(file.path(path, "HMP_MOCK.v35.fasta"))
match.ref <- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))
cat("Of those,", sum(match.ref), "were exact matches to the expected reference sequences.\n")
```

# Chargement du package phyloseq
# Vérification de la version installée
#Il est conçu pour faciliter l’intégration, la manipulation et la visualisation de données issues de pipelines comme DADA2
```{r}
library(phyloseq); packageVersion("phyloseq")
```

# Chargement du package Biostrings
# Vérification de la version installée
#charge le package Biostrings, qui fournit des classes et fonctions pour manipuler efficacement des séquences biologiques (ADN, ARN, protéines).

```{r}
library(Biostrings); packageVersion("Biostrings")
```

# Chargement du package ggplot2
# Vérification de la version installée
#charge le package ggplot2, qui fait partie du tidyverse et permet de créer des graphiques élégants et personnalisés.

```{r}
library(ggplot2); packageVersion("ggplot2")
```
# Définit le thème par défaut pour tous les graphiques ggplot2
#permet de changer le thème global appliqué à tous tes graphiques ggplot2

```{r}
theme_set(theme_bw())
```

# Récupère les noms des échantillons (correspondent aux lignes de la table ASV)
# Sépare le nom de l’échantillon sur le "D" et prend la première partie (= sujet/identifiant)
# Le premier caractère du "subject" = le genre (M = male, F = female)
# Le reste du "subject" (après le 1er caractère) = identifiant du sujet
# Deuxième partie après "D" = numéro du jour (converti en entier)
# Création d’un data.frame avec les colonnes Sujet, Genre et Jour
# Ajout d’une variable "When" = précoce (Day ≤ 100) ou tardif (Day > 100)
# Les noms des lignes du data.frame sont les noms des échantillons
#ça m'a permi de créer une table de métadonnées par échantillon (sujets, genre, jour, période)

```{r}
samples.out <- rownames(seqtab.nochim)
subject <- sapply(strsplit(samples.out, "D"), `[`, 1)
gender <- substr(subject,1,1)
subject <- substr(subject,2,999)
day <- as.integer(sapply(strsplit(samples.out, "D"), `[`, 2))
samdf <- data.frame(Subject=subject, Gender=gender, Day=day)
samdf$When <- "Early"
samdf$When[samdf$Day>100] <- "Late"
rownames(samdf) <- samples.out
```


# Création de l’objet phyloseq avec :
# - table d’abondances des ASVs
# - métadonnées des échantillons
# - taxonomie
# je retire l’échantillon "Mock" qui servait de témoin

```{r}
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa))
ps <- prune_samples(sample_names(ps) != "Mock", ps) # Remove mock sample
```

# Crée un objet DNAStringSet avec les séquences des ASVs
# Donne comme noms aux séquences leurs noms actuels (longues séquences nucléotidiques)
# Ajoute ces séquences à l’objet phyloseq (fusionne tables + séquences)
# Renomme les ASVs avec des IDs courts et lisibles (ASV1, ASV2, …)
# Affiche l’objet phyloseq (résumé de sa structure : nb échantillons, ASVs, taxons…)
#Les séquences brutes sont trop longues pour servir de noms → peu lisibles dans les graphiques ou les tableaux.
#En les renommant ASV1, ASV2, … je simplifi l’affichage, tout en conservant les séquences dans l’objet si besoin pour alignement ou phylogénie.

```{r}
dna <- Biostrings::DNAStringSet(taxa_names(ps))
names(dna) <- taxa_names(ps)
ps <- merge_phyloseq(ps, dna)
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))
ps
```


# Trace la diversité alpha en fonction du jour d’échantillonnage
#ps, objet phyloseq
#x = "Day"variable en abscisse = jour
#measures = c("Shannon","Simpson"),
#indices de diversité alpha calculés
#ce graphique me montre comment la diversité microbienne évolue avec le temps (Day) et selon la période définie (When = Early vs Late).

```{r}
plot_richness(ps, x="Day", measures=c("Shannon", "Simpson"), color="When")
```


# Met la table d'abondances au format "proportions" (abondances relatives par échantillon)
# Chaque ligne (échantillon) est divisée par sa somme → somme = 1
# Réalise une ordination NMDS en distance de Bray–Curtis sur les abondances relatives
ord.nmds.bray <- ordinate(ps.prop, method = "NMDS", distance = "bray")
# Couleurs par When (Early/Late), formes par Gender, par ex.
plot_ordination(ps.prop, ord.nmds.bray, color = "When", shape = "Gender") +
  geom_point(size = 3) +
  labs(title = "NMDS (Bray–Curtis) sur abondances relatives")
```{r}
# Transform data to proportions as appropriate for Bray-Curtis distances
ps.prop <- transform_sample_counts(ps, function(otu) otu/sum(otu))
ord.nmds.bray <- ordinate(ps.prop, method="NMDS", distance="bray")
```

# Trace l’ordination NMDS calculée précédemment
#plot_ordination() : fonction phyloseq pour représenter une ordination (ordinate)

```{r}
plot_ordination(ps.prop, ord.nmds.bray, color="When", title="Bray NMDS")
```

# Identifie les 20 ASVs les plus abondants (somme sur tous les échantillons)
# Transforme les abondances en proportions par échantillon
# Garde uniquement les 20 ASVs les plus abondant
# Trace un barplot empilé par échantillon (x=Day), avec les familles en couleurs
# et facettes séparées selon la variable "When" (Early vs Late)
```{r}
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x="Day", fill="Family") + facet_wrap(~When, scales="free_x")
```



